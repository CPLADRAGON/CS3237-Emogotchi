{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ccaff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ca2754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'scored_sensor_data.csv' successfully.\n",
      "Features and target have been scaled.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Data ---\n",
    "try:\n",
    "    data = pd.read_csv(\"scored_sensor_data.csv\")\n",
    "    print(\"Loaded 'scored_sensor_data.csv' successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'scored_sensor_data.csv' not found.\")\n",
    "    \n",
    "# --- 2. Define Features and Target ---\n",
    "features = ['bpm', 'temperature', 'humidity', 'noise', 'ldr', 'in_motion']\n",
    "target = 'happiness_score'\n",
    "\n",
    "# --- 3. Create and Fit Scalers ---\n",
    "# Feature Scaler (StandardScaler): Centers data around 0. Good for inputs.\n",
    "feature_scaler = StandardScaler()\n",
    "X_scaled = feature_scaler.fit_transform(data[features])\n",
    "\n",
    "# Target Scaler (MinMaxScaler): Scales data to 0-1. Best for regression outputs.\n",
    "target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaled = target_scaler.fit_transform(data[[target]])\n",
    "\n",
    "print(\"Features and target have been scaled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e8bf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f1d1663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequenced features shape: (1040, 10, 6)\n",
      "Sequenced target shape: (1040, 1)\n",
      "Training data shape: (832, 10, 6), Testing data shape: (208, 10, 6)\n",
      "\n",
      "Building LSTM model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 64)            18176     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 64)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                528       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31137 (121.63 KB)\n",
      "Trainable params: 31137 (121.63 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training LSTM model...\n",
      "Epoch 1/50\n",
      "24/24 [==============================] - 4s 42ms/step - loss: 0.1010 - val_loss: 0.0092\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0048\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0049\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0047\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0038\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0043\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0120 - val_loss: 0.0037\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0039\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0042\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0037\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0037\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0030\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0031\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0029\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0027\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0027\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0027\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0026\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0027\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0025\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0026\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0026\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0026\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0025\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0026\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0073 - val_loss: 0.0026\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0025\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0025\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0025\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0026\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0026\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0028\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0026\n",
      "LSTM model and scalers saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Create Time-Series Sequences ---\n",
    "def create_sequences(X, y, time_steps=10):\n",
    "    \"\"\"Converts data into 3D sequences for the LSTM.\"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps)])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "TIME_STEPS = 10  # Each sample will be 10 steps of sensor data\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, TIME_STEPS)\n",
    "\n",
    "print(f\"Sequenced features shape: {X_seq.shape}\") # (Samples, Time Steps, Features)\n",
    "print(f\"Sequenced target shape: {y_seq.shape}\")\n",
    "\n",
    "# --- 2. Split Data ---\n",
    "# shuffle=False is critical for time-series data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42, shuffle=False)\n",
    "print(f\"Training data shape: {X_train.shape}, Testing data shape: {X_test.shape}\")\n",
    "\n",
    "# --- 3. Build the LSTM Model ---\n",
    "print(\"\\nBuilding LSTM model...\")\n",
    "n_features = X_seq.shape[2]  # 6 features\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(units=64, return_sequences=True, input_shape=(TIME_STEPS, n_features)))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(LSTM(units=32))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(units=16, activation='relu'))\n",
    "# Final layer for regression: 1 unit, linear activation\n",
    "model_lstm.add(Dense(units=1, activation='linear')) \n",
    "\n",
    "# Compile with a regression loss function\n",
    "model_lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_lstm.summary()\n",
    "\n",
    "# --- 4. Train the Model ---\n",
    "print(\"\\nTraining LSTM model...\")\n",
    "# EarlyStopping will stop training if the validation loss doesn't improve\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model_lstm.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,  # Train for more epochs, EarlyStopping will stop it\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True, \n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# --- 5. Save Model and Scalers ---\n",
    "model_lstm.save('emogotchi_lstm_regressor.keras')\n",
    "joblib.dump(feature_scaler, 'sensor_scaler.pkl')\n",
    "joblib.dump(target_scaler, 'target_scaler.pkl')\n",
    "print(\"LSTM model and scalers saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2588f6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded LSTM model and both scalers for Rules Engine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- 1. Load All Saved Components ---\n",
    "try:\n",
    "    model = load_model('emogotchi_lstm_regressor.keras')\n",
    "    feature_scaler = joblib.load('sensor_scaler.pkl')\n",
    "    target_scaler = joblib.load('target_scaler.pkl')\n",
    "    print(\"Successfully loaded LSTM model and both scalers for Rules Engine.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models. Make sure you have run the training pipeline first.\\n{e}\")\n",
    "\n",
    "features = ['bpm', 'temperature', 'humidity', 'noise', 'ldr', 'in_motion']\n",
    "\n",
    "def get_happiness_score(sensor_sequence):\n",
    "    \"\"\"\n",
    "    Takes a sequence of 10 sensor data dictionaries, checks hard thresholds,\n",
    "    runs the LSTM model, and returns only the 0-100 score.\n",
    "    \n",
    "    :param sensor_sequence: A list of 10 dictionaries, from oldest to newest.\n",
    "    :return: A float (0-100) representing the happiness score.\n",
    "    \"\"\"\n",
    "    emotion_score = -1\n",
    "    \n",
    "    # Get the MOST RECENT sensor reading\n",
    "    latest_reading = sensor_sequence[-1]\n",
    "    \n",
    "    # --- 1. Check Hard Thresholds First ---\n",
    "    if latest_reading['bpm'] > 130 and latest_reading['in_motion'] == 0:\n",
    "        emotion_score = 10.0\n",
    "    elif latest_reading['temperature'] > 32:\n",
    "        emotion_score = 15.0\n",
    "    \n",
    "    # --- 2. If no hard rule, use LSTM Model ---\n",
    "    if emotion_score == -1:\n",
    "        try:\n",
    "            # Convert list of dicts to 2D numpy array\n",
    "            data_list = [[reading[f] for f in features] for reading in sensor_sequence]\n",
    "            data_array = np.array(data_list)\n",
    "            \n",
    "            # Scale features\n",
    "            data_scaled = feature_scaler.transform(data_array)\n",
    "            \n",
    "            # Reshape for LSTM: (1 sample, 10 time steps, 6 features)\n",
    "            data_lstm = np.expand_dims(data_scaled, axis=0)\n",
    "            \n",
    "            # Predict the *scaled* emotion score\n",
    "            scaled_score = model.predict(data_lstm, verbose=0)[0]\n",
    "            \n",
    "            # Inverse-transform the score to 0-100\n",
    "            emotion_score = target_scaler.inverse_transform(scaled_score.reshape(-1, 1))[0][0]\n",
    "            \n",
    "            # Clip score to be safe (0-100)\n",
    "            emotion_score = np.clip(emotion_score, 0, 100)\n",
    "            \n",
    "        except Exception:\n",
    "            # On error, default to 'plain' score without printing\n",
    "            emotion_score = 50.0\n",
    "        \n",
    "    # --- 3. Return only the numeric score ---\n",
    "    return round(emotion_score, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS3237",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
