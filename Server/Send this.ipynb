{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccaff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca2754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'scored_sensor_data.csv' successfully.\n",
      "Features and target have been scaled.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Data ---\n",
    "try:\n",
    "    data = pd.read_csv(\"scored_sensor_data.csv\")\n",
    "    print(\"Loaded 'scored_sensor_data.csv' successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'scored_sensor_data.csv' not found.\")\n",
    "    \n",
    "# --- 2. Define Features and Target ---\n",
    "features = ['bpm', 'temperature', 'humidity', 'noise', 'ldr', 'in_motion']\n",
    "target = 'happiness_score'\n",
    "\n",
    "# --- 3. Create and Fit Scalers ---\n",
    "# Feature Scaler (StandardScaler): Centers data around 0. Good for inputs.\n",
    "feature_scaler = StandardScaler()\n",
    "X_scaled = feature_scaler.fit_transform(data[features])\n",
    "\n",
    "# Target Scaler (MinMaxScaler): Scales data to 0-1. Best for regression outputs.\n",
    "target_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaled = target_scaler.fit_transform(data[[target]])\n",
    "\n",
    "print(\"Features and target have been scaled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f1d1663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequenced features shape: (1040, 10, 6)\n",
      "Sequenced target shape: (1040, 1)\n",
      "Training data shape: (832, 10, 6), Testing data shape: (208, 10, 6)\n",
      "\n",
      "Building LSTM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dongh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m18,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,137</span> (121.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,137\u001b[0m (121.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,137</span> (121.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,137\u001b[0m (121.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LSTM model...\n",
      "Epoch 1/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.1495 - val_loss: 0.0056\n",
      "Epoch 2/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0282 - val_loss: 0.0023\n",
      "Epoch 3/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0183 - val_loss: 0.0031\n",
      "Epoch 4/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0171 - val_loss: 0.0034\n",
      "Epoch 5/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0155 - val_loss: 0.0036\n",
      "Epoch 6/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0129 - val_loss: 0.0044\n",
      "Epoch 7/50\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0125 - val_loss: 0.0035\n",
      "LSTM model and scalers saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Create Time-Series Sequences ---\n",
    "def create_sequences(X, y, time_steps=10):\n",
    "    \"\"\"Converts data into 3D sequences for the LSTM.\"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:(i + time_steps)])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "TIME_STEPS = 10  # Each sample will be 10 steps of sensor data\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, TIME_STEPS)\n",
    "\n",
    "print(f\"Sequenced features shape: {X_seq.shape}\") # (Samples, Time Steps, Features)\n",
    "print(f\"Sequenced target shape: {y_seq.shape}\")\n",
    "\n",
    "# --- 2. Split Data ---\n",
    "# shuffle=False is critical for time-series data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42, shuffle=False)\n",
    "print(f\"Training data shape: {X_train.shape}, Testing data shape: {X_test.shape}\")\n",
    "\n",
    "# --- 3. Build the LSTM Model ---\n",
    "print(\"\\nBuilding LSTM model...\")\n",
    "n_features = X_seq.shape[2]  # 6 features\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(units=64, return_sequences=True, input_shape=(TIME_STEPS, n_features)))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(LSTM(units=32))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(units=16, activation='relu'))\n",
    "# Final layer for regression: 1 unit, linear activation\n",
    "model_lstm.add(Dense(units=1, activation='linear')) \n",
    "\n",
    "# Compile with a regression loss function\n",
    "model_lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_lstm.summary()\n",
    "\n",
    "# --- 4. Train the Model ---\n",
    "print(\"\\nTraining LSTM model...\")\n",
    "# EarlyStopping will stop training if the validation loss doesn't improve\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model_lstm.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,  # Train for more epochs, EarlyStopping will stop it\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True, \n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# --- 5. Save Model and Scalers ---\n",
    "model_lstm.save('emogotchi_lstm_regressor.keras')\n",
    "joblib.dump(feature_scaler, 'sensor_scaler.pkl')\n",
    "joblib.dump(target_scaler, 'target_scaler.pkl')\n",
    "print(\"LSTM model and scalers saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2588f6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded LSTM model and both scalers for Rules Engine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- 1. Load All Saved Components ---\n",
    "try:\n",
    "    model = load_model('emogotchi_lstm_regressor.keras')\n",
    "    feature_scaler = joblib.load('sensor_scaler.pkl')\n",
    "    target_scaler = joblib.load('target_scaler.pkl')\n",
    "    print(\"Successfully loaded LSTM model and both scalers for Rules Engine.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models. Make sure you have run the training pipeline first.\\n{e}\")\n",
    "\n",
    "features = ['bpm', 'temperature', 'humidity', 'noise', 'ldr', 'in_motion']\n",
    "\n",
    "def get_happiness_score(sensor_sequence):\n",
    "    \"\"\"\n",
    "    Takes a sequence of 10 sensor data dictionaries, checks hard thresholds,\n",
    "    runs the LSTM model, and returns only the 0-100 score.\n",
    "    \n",
    "    :param sensor_sequence: A list of 10 dictionaries, from oldest to newest.\n",
    "    :return: A float (0-100) representing the happiness score.\n",
    "    \"\"\"\n",
    "    emotion_score = -1\n",
    "    \n",
    "    # Get the MOST RECENT sensor reading\n",
    "    latest_reading = sensor_sequence[-1]\n",
    "    \n",
    "    # --- 1. Check Hard Thresholds First ---\n",
    "    if latest_reading['bpm'] > 130 and latest_reading['in_motion'] == 0:\n",
    "        emotion_score = 10.0\n",
    "    elif latest_reading['temperature'] > 32:\n",
    "        emotion_score = 15.0\n",
    "    \n",
    "    # --- 2. If no hard rule, use LSTM Model ---\n",
    "    if emotion_score == -1:\n",
    "        try:\n",
    "            # Convert list of dicts to 2D numpy array\n",
    "            data_list = [[reading[f] for f in features] for reading in sensor_sequence]\n",
    "            data_array = np.array(data_list)\n",
    "            \n",
    "            # Scale features\n",
    "            data_scaled = feature_scaler.transform(data_array)\n",
    "            \n",
    "            # Reshape for LSTM: (1 sample, 10 time steps, 6 features)\n",
    "            data_lstm = np.expand_dims(data_scaled, axis=0)\n",
    "            \n",
    "            # Predict the *scaled* emotion score\n",
    "            scaled_score = model.predict(data_lstm, verbose=0)[0]\n",
    "            \n",
    "            # Inverse-transform the score to 0-100\n",
    "            emotion_score = target_scaler.inverse_transform(scaled_score.reshape(-1, 1))[0][0]\n",
    "            \n",
    "            # Clip score to be safe (0-100)\n",
    "            emotion_score = np.clip(emotion_score, 0, 100)\n",
    "            \n",
    "        except Exception:\n",
    "            # On error, default to 'plain' score without printing\n",
    "            emotion_score = 50.0\n",
    "        \n",
    "    # --- 3. Return only the numeric score ---\n",
    "    return round(emotion_score, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
